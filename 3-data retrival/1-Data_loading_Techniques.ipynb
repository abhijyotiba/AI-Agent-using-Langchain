{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "974c2fd5",
   "metadata": {},
   "source": [
    "# DATA Loading from Different File Types, Creating Embeddings, and Storing in a Vector Database\n",
    "\n",
    "This notebook demonstrates how to load data from various file types, generate embeddings, and store them in a vector database for efficient retrieval and search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "be7be9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader, WebBaseLoader, CSVLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94d2e549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document loaders created successfully!\n",
      "Files being loaded:\n"
     ]
    }
   ],
   "source": [
    "text_loader = TextLoader(file_path=\"d:/Langchain Tutorial/data retrival/langchain.txt\")\n",
    "pdf_loader = PyPDFLoader(file_path=\"d:/Langchain Tutorial/data retrival/Medical_book.pdf\")\n",
    "web_loader = WebBaseLoader(web_path=\"https://langchain-ai.github.io/langgraph/concepts/why-langgraph/\")\n",
    "csv_loader = CSVLoader(file_path=\"d:/Langchain Tutorial/data retrival/sample_financial_data.csv\")\n",
    "\n",
    "\n",
    "print(\"Document loaders created successfully!\")\n",
    "print(\"Files being loaded:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01eb1a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'd:/Langchain Tutorial/data retrival/langchain.txt'}, page_content='LangChain is an open-source framework designed to help developers build applications using Large Language Models (LLMs) like GPT-4. It provides tools and abstractions that make it easier to integrate LLMs with:\\n\\nExternal data sources (like databases, PDFs, web pages, or APIs)\\n\\nReasoning and memory (handling multi-step tasks or tracking conversation history)\\n\\nTool use (such as calling APIs or executing code)\\n\\nAgents that can make decisions dynamically based on LLM outputs\\n\\nðŸ”§ Core Features of LangChain\\nChains\\nCombine multiple steps (e.g., prompt -> LLM -> output formatting) into a sequence.\\n\\nAgents\\nUse LLMs to make decisions and choose which tools to call (e.g., a calculator, search engine).\\n\\nTools & Integrations\\nPlug in external tools like:\\n\\nGoogle Search\\n\\nSQL databases\\n\\nPython REPL\\n\\nWolframAlpha\\n\\nZapier, etc.\\n\\nMemory\\nStore and use conversation history, enabling stateful chatbots.\\n\\nRetrieval-Augmented Generation (RAG)\\nPull in relevant documents from your data (PDFs, Notion, vector databases like Pinecone or FAISS) before generating a response.\\n\\nOutput Parsers\\nConvert the LLM output into a usable format like structured JSON, markdown, etc.\\n\\nðŸ§\\xa0 Why Use LangChain?\\nYou want more control than just sending prompts to ChatGPT.\\n\\nYou\\'re building apps like:\\n\\nChatbots with memory\\n\\nQ&A systems over private data\\n\\nLLM-powered agents or assistants\\n\\nCustom workflows using tools + LLMs\\n\\nðŸš€ Quick Example\\npython\\nCopy\\nEdit\\nfrom langchain.llms import OpenAI\\nfrom langchain.chains.question_answering import load_qa_chain\\nfrom langchain.document_loaders import TextLoader\\n\\nloader = TextLoader(\"my_text.txt\")\\ndocuments = loader.load()\\n\\nllm = OpenAI(temperature=0)\\nchain = load_qa_chain(llm, chain_type=\"stuff\")\\n\\nquestion = \"What is LangChain?\"\\nresult = chain.run(input_documents=documents, question=question)\\nprint(result)\\nðŸ§° LangChain Works Well With:\\nOpenAI, Anthropic, Cohere, etc.\\n\\nVector DBs: Pinecone, Weaviate, FAISS, Chroma\\n\\nFrameworks: Streamlit, FastAPI, Gradio\\n\\nOrchestration tools: Airflow, LangServe, LangSmith\\n\\nIf you\\'re planning to build a production-ready AI app, LangChain gives you the building blocks to do it effectively.\\n\\nWant a demo or example for a specific use case?')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_loader = TextLoader(file_path=\"d:/Langchain Tutorial/data retrival/langchain.txt\")\n",
    "text_docs = text_loader.load()\n",
    "\n",
    "text_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8f225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_loader = PyPDFLoader(file_path=\"d:/Langchain Tutorial/data retrival/Medical_book.pdf\")\n",
    "\n",
    "pdf_docs = pdf_loader.load()\n",
    "pdf_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59e09d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/concepts/why-langgraph/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content=\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\nWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.  Join our team!\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Overview\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Get started\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Additional resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Get started\\n          \\n\\n\\n\\n\\n\\n    Quickstarts\\n    \\n  \\n\\n\\n\\n\\n\\n            Quickstarts\\n          \\n\\n\\n\\n\\n    Start with a prebuilt agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Build a custom workflow\\n    \\n  \\n\\n\\n\\n\\n\\n            Build a custom workflow\\n          \\n\\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Learn LangGraph basics\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n    1. Build a basic chatbot\\n    \\n  \\n\\n\\n\\n\\n\\n    2. Add tools\\n    \\n  \\n\\n\\n\\n\\n\\n    3. Add memory\\n    \\n  \\n\\n\\n\\n\\n\\n    4. Add human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    5. Customize state\\n    \\n  \\n\\n\\n\\n\\n\\n    6. Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Run a local server\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Agent development\\n    \\n  \\n\\n\\n\\n\\n\\n            Agent development\\n          \\n\\n\\n\\n\\n    Workflows & agents\\n    \\n  \\n\\n\\n\\n\\n\\n    Prebuilt components\\n    \\n  \\n\\n\\n\\n\\n\\n    Run an agent\\n    \\n  \\n\\n\\n\\n\\n\\n    Agent architectures\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Additional resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Learn LangGraph basics\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOverview¶\\nLangGraph is built for developers who want to build powerful, adaptable AI agents. Developers choose LangGraph for:\\n\\nReliability and controllability. Steer agent actions with moderation checks and human-in-the-loop approvals. LangGraph persists context for long-running workflows, keeping your agents on course.\\nLow-level and extensible. Build custom agents with fully descriptive, low-level primitives free from rigid abstractions that limit customization. Design scalable multi-agent systems, with each agent serving a specific role tailored to your use case.\\nFirst-class streaming support. With token-by-token streaming and streaming of intermediate steps, LangGraph gives users clear visibility into agent reasoning and actions as they unfold in real time.\\n\\nLearn LangGraph basics¶\\nTo get acquainted with LangGraph's key concepts and features, complete the following LangGraph basics tutorials series:\\n\\nBuild a basic chatbot\\nAdd tools\\nAdd memory\\nAdd human-in-the-loop controls\\nCustomize state\\nTime travel\\n\\nIn completing this series of tutorials, you will build a support chatbot in LangGraph that can:\\n\\n✅ Answer common questions by searching the web\\n✅ Maintain conversation state across calls  \\n✅ Route complex queries to a human for review  \\n✅ Use custom state to control its behavior  \\n✅ Rewind and explore alternative conversation paths  \\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Start with a prebuilt agent\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                1. Build a basic chatbot\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\")]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "web_loader = WebBaseLoader(web_path=\"https://langchain-ai.github.io/langgraph/concepts/why-langgraph/\")\n",
    "\n",
    "web_docs = web_loader.load()\n",
    "web_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d89f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "682"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_loader = CSVLoader(file_path=\"d:/Langchain Tutorial/data retrival/sample_financial_data.csv\")\n",
    "\n",
    "csv_docs = csv_loader.load()\n",
    "csv_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69ffcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_docs = text_docs + csv_docs + pdf_docs + web_docs\n",
    "len(final_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4e234a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of chunks: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=100)\n",
    "\n",
    "chunks_document = text_splitter.split_documents(final_docs)\n",
    "\n",
    "print('No of chunks:', len(chunks_document))\n",
    "type(chunks_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b107ccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# def create_embedding():\n",
    "#     embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "#     return embedding\n",
    "\n",
    "# embedding = create_embedding()\n",
    "# embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b1b57e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embed = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text:latest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "48228a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "db=Chroma.from_documents(chunks_document,embed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "89b50112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x232f637ffe0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fb357646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'd:/Langchain Tutorial/data retrival/langchain.txt'}, page_content=\"Frameworks: Streamlit, FastAPI, Gradio\\n\\nOrchestration tools: Airflow, LangServe, LangSmith\\n\\nIf you're planning to build a production-ready AI app, LangChain gives you the building blocks to do it effectively.\\n\\nWant a demo or example for a specific use case?\"),\n",
       " Document(metadata={'source': 'd:/Langchain Tutorial/data retrival/langchain.txt'}, page_content='Agents that can make decisions dynamically based on LLM outputs\\n\\nðŸ”§ Core Features of LangChain\\nChains\\nCombine multiple steps (e.g., prompt -> LLM -> output formatting) into a sequence.\\n\\nAgents\\nUse LLMs to make decisions and choose which tools to call (e.g., a calculator, search engine).\\n\\nTools & Integrations\\nPlug in external tools like:\\n\\nGoogle Search\\n\\nSQL databases\\n\\nPython REPL\\n\\nWolframAlpha\\n\\nZapier, etc.\\n\\nMemory\\nStore and use conversation history, enabling stateful chatbots.'),\n",
       " Document(metadata={'source': 'd:/Langchain Tutorial/data retrival/langchain.txt'}, page_content='LangChain is an open-source framework designed to help developers build applications using Large Language Models (LLMs) like GPT-4. It provides tools and abstractions that make it easier to integrate LLMs with:\\n\\nExternal data sources (like databases, PDFs, web pages, or APIs)\\n\\nReasoning and memory (handling multi-step tasks or tracking conversation history)\\n\\nTool use (such as calling APIs or executing code)\\n\\nAgents that can make decisions dynamically based on LLM outputs'),\n",
       " Document(metadata={'source': 'd:/Langchain Tutorial/data retrival/langchain.txt'}, page_content='llm = OpenAI(temperature=0)\\nchain = load_qa_chain(llm, chain_type=\"stuff\")\\n\\nquestion = \"What is LangChain?\"\\nresult = chain.run(input_documents=documents, question=question)\\nprint(result)\\nðŸ§° LangChain Works Well With:\\nOpenAI, Anthropic, Cohere, etc.\\n\\nVector DBs: Pinecone, Weaviate, FAISS, Chroma\\n\\nFrameworks: Streamlit, FastAPI, Gradio\\n\\nOrchestration tools: Airflow, LangServe, LangSmith')]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"india\"\n",
    "result=db.similarity_search(query=query)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "edd53037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'd:/Langchain Tutorial/data retrival/langchain.txt'}, page_content='LangChain is an open-source framework designed to help developers build applications using Large Language Models (LLMs) like GPT-4. It provides tools and abstractions that make it easier to integrate LLMs with:\\n\\nExternal data sources (like databases, PDFs, web pages, or APIs)\\n\\nReasoning and memory (handling multi-step tasks or tracking conversation history)\\n\\nTool use (such as calling APIs or executing code)\\n\\nAgents that can make decisions dynamically based on LLM outputs')]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever(\n",
    "    search_type=\"mmr\", search_kwargs={\"k\": 1, \"fetch_k\": 5}\n",
    ")\n",
    "result1 =retriever.invoke(\"what is langchain\")\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a302eec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4791dca",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
